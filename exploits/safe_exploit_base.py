#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SafeExploitBase - Secure base class for all ChromSploit exploits
Implements mandatory safety controls and simulation mode
"""

import os
import sys
import json
import time
import logging
import hashlib
import tempfile
from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from pathlib import Path

# ChromSploit imports
try:
    from core.enhanced_logger import get_logger
    from core.colors import Colors
    logger = get_logger()
except ImportError:
    logger = logging.getLogger(__name__)
    
    # Fallback Colors class
    class Colors:
        END = ''
        RED = ''
        GREEN = ''
        YELLOW = ''
        BLUE = ''
        CYAN = ''
        MAGENTA = ''


class SafetyMode:
    """Safety mode constants"""
    SIMULATION = "simulation"
    AUTHORIZED = "authorized"
    DEMONSTRATION = "demonstration"
    EDUCATIONAL = "educational"


class ExploitAuthorization:
    """Handle exploit authorization and safety checks"""
    
    def __init__(self):
        self.authorization_file = Path("/tmp/.chromsploit_auth.json")
        self.authorized_exploits = set()
        self.load_authorizations()
    
    def load_authorizations(self):
        """Load existing authorizations"""
        try:
            if self.authorization_file.exists():
                with open(self.authorization_file, 'r') as f:
                    data = json.load(f)
                    self.authorized_exploits = set(data.get('authorized_exploits', []))
        except Exception:
            pass
    
    def save_authorizations(self):
        """Save authorizations to file"""
        try:
            data = {
                'authorized_exploits': list(self.authorized_exploits),
                'last_updated': datetime.now().isoformat()
            }
            with open(self.authorization_file, 'w') as f:
                json.dump(data, f, indent=2)
        except Exception:
            pass
    
    def is_authorized(self, exploit_id: str) -> bool:
        """Check if exploit is authorized"""
        return exploit_id in self.authorized_exploits
    
    def authorize(self, exploit_id: str, auth_code: str) -> bool:
        """Authorize an exploit with proper code"""
        # In production, this would verify against a secure authorization system
        # For now, we use a simple hash check
        expected_hash = hashlib.sha256(f"CHROMSPLOIT_AUTH_{exploit_id}_2025".encode()).hexdigest()
        
        if auth_code == expected_hash[:16]:  # First 16 chars of hash
            self.authorized_exploits.add(exploit_id)
            self.save_authorizations()
            return True
        return False
    
    def revoke(self, exploit_id: str):
        """Revoke authorization for an exploit"""
        self.authorized_exploits.discard(exploit_id)
        self.save_authorizations()


class SafeExploitBase(ABC):
    """Base class for all safe exploits in ChromSploit Framework"""
    
    def __init__(self, cve_id: str, name: str, description: str):
        self.cve_id = cve_id
        self.name = name
        self.description = description
        self.safety_mode = SafetyMode.SIMULATION  # Default to simulation
        self.authorization = ExploitAuthorization()
        self.config = {}
        self.simulation_logs = []
        self.safety_checks_passed = False
        self.execution_id = None
        
        # Logging setup
        self.logger = logger
        
        # Initialize exploit
        self._initialize()
    
    def _initialize(self):
        """Initialize exploit with safety measures"""
        try:
            self.logger.info(f"{Colors.CYAN}[SAFETY]{Colors.END} Initializing {self.cve_id} in SAFE mode")
            self.logger.info(f"{Colors.YELLOW}[MODE]{Colors.END} Default mode: {self.safety_mode}")
        except:
            self.logger.info(f"Initializing {self.cve_id} in SAFE mode")
            self.logger.info(f"Default mode: {self.safety_mode}")
    
    def set_parameter(self, name: str, value: Any):
        """Set exploit parameter with validation"""
        # Validate parameter before setting
        if self._validate_parameter(name, value):
            self.config[name] = value
            self._log_safe(f"Set parameter {name} = {value}")
        else:
            self._log_warning(f"Invalid parameter rejected: {name} = {value}")
    
    def _validate_parameter(self, name: str, value: Any) -> bool:
        """Validate parameter safety"""
        # Block dangerous values
        dangerous_patterns = [
            'rm -rf',
            'format c:',
            '/dev/zero',
            'fork bomb',
            ':(){ :|:& };:',
            'dd if=',
        ]
        
        value_str = str(value).lower()
        for pattern in dangerous_patterns:
            if pattern in value_str:
                return False
        
        return True
    
    def set_safety_mode(self, mode: str, auth_code: str = None) -> bool:
        """Set safety mode with proper authorization"""
        if mode == SafetyMode.SIMULATION:
            self.safety_mode = mode
            self._log_safe(f"Safety mode set to: {mode}")
            return True
        
        elif mode == SafetyMode.AUTHORIZED:
            if auth_code and self.authorization.authorize(self.cve_id, auth_code):
                self.safety_mode = mode
                self._log_warning(f"AUTHORIZED mode enabled for {self.cve_id}")
                self._create_audit_log("AUTHORIZED_MODE_ENABLED")
                return True
            else:
                self._log_error("Authorization failed - invalid auth code")
                return False
        
        elif mode in [SafetyMode.DEMONSTRATION, SafetyMode.EDUCATIONAL]:
            self.safety_mode = mode
            self._log_safe(f"Safety mode set to: {mode}")
            return True
        
        else:
            self._log_error(f"Invalid safety mode: {mode}")
            return False
    
    def execute(self, target_url: str = None) -> Dict[str, Any]:
        """Execute exploit with safety controls"""
        try:
            # Generate execution ID
            self.execution_id = f"{self.cve_id}_{int(time.time())}_{os.urandom(4).hex()}"
            
            # Create audit log
            self._create_audit_log("EXECUTION_STARTED")
            
            # Perform safety checks
            if not self._perform_safety_checks():
                return self._create_safe_failure_response("Safety checks failed")
            
            # Log execution mode
            self._log_safe(f"Executing {self.cve_id} in {self.safety_mode} mode")
            
            # Execute based on safety mode
            if self.safety_mode == SafetyMode.SIMULATION:
                result = self._execute_simulation(target_url)
            elif self.safety_mode == SafetyMode.AUTHORIZED:
                # Double-check authorization
                if self.authorization.is_authorized(self.cve_id):
                    result = self._execute_real(target_url)
                else:
                    return self._create_safe_failure_response("Authorization revoked")
            elif self.safety_mode == SafetyMode.DEMONSTRATION:
                result = self._execute_demonstration(target_url)
            elif self.safety_mode == SafetyMode.EDUCATIONAL:
                result = self._execute_educational(target_url)
            else:
                return self._create_safe_failure_response("Invalid safety mode")
            
            # Add safety metadata to result
            result['safety_metadata'] = {
                'mode': self.safety_mode,
                'execution_id': self.execution_id,
                'safety_checks_passed': self.safety_checks_passed,
                'simulation_logs': self.simulation_logs if self.safety_mode == SafetyMode.SIMULATION else []
            }
            
            # Create audit log
            self._create_audit_log("EXECUTION_COMPLETED", result)
            
            return result
            
        except Exception as e:
            self._log_error(f"Execution failed safely: {e}")
            return self._create_safe_failure_response(str(e))
    
    def _perform_safety_checks(self) -> bool:
        """Perform comprehensive safety checks"""
        checks = []
        
        # Check 1: Target validation
        if 'target_url' in self.config or hasattr(self, 'target_url'):
            target = self.config.get('target_url', getattr(self, 'target_url', None))
            if target and not self._is_safe_target(target):
                checks.append(('target_validation', False, 'Unsafe target detected'))
            else:
                checks.append(('target_validation', True, 'Target validated'))
        
        # Check 2: Payload safety
        if not self._validate_payloads():
            checks.append(('payload_validation', False, 'Unsafe payload detected'))
        else:
            checks.append(('payload_validation', True, 'Payloads validated'))
        
        # Check 3: Network safety
        if not self._validate_network_safety():
            checks.append(('network_validation', False, 'Unsafe network configuration'))
        else:
            checks.append(('network_validation', True, 'Network configuration safe'))
        
        # Check 4: File system safety
        if not self._validate_filesystem_safety():
            checks.append(('filesystem_validation', False, 'Unsafe file operations'))
        else:
            checks.append(('filesystem_validation', True, 'File operations safe'))
        
        # Log all checks
        for check_name, passed, message in checks:
            if passed:
                self._log_safe(f"Safety check passed: {check_name} - {message}")
            else:
                self._log_warning(f"Safety check failed: {check_name} - {message}")
        
        # All checks must pass
        self.safety_checks_passed = all(check[1] for check in checks)
        return self.safety_checks_passed
    
    def _is_safe_target(self, target: str) -> bool:
        """Check if target is safe to test"""
        # Allow localhost and private IPs only
        safe_targets = [
            '127.0.0.1',
            'localhost',
            '0.0.0.0',
            '10.',
            '172.16.',
            '192.168.',
            'testlab.',
            'demo.',
            'example.'
        ]
        
        target_lower = str(target).lower()
        return any(safe in target_lower for safe in safe_targets)
    
    def _validate_payloads(self) -> bool:
        """Validate all payloads are safe"""
        # Override in subclasses for specific validation
        return True
    
    def _validate_network_safety(self) -> bool:
        """Validate network operations are safe"""
        # Check callback IPs are local
        callback_params = ['callback_ip', 'rhost', 'lhost', 'server_ip']
        
        for param in callback_params:
            if param in self.config:
                if not self._is_safe_target(self.config[param]):
                    return False
        
        return True
    
    def _validate_filesystem_safety(self) -> bool:
        """Validate file system operations are safe"""
        # Ensure all file operations are in safe directories
        safe_dirs = ['/tmp/', '/var/tmp/', tempfile.gettempdir()]
        
        # Override in subclasses for specific validation
        return True
    
    def _create_audit_log(self, event: str, data: Dict[str, Any] = None):
        """Create audit log for security tracking"""
        audit_entry = {
            'timestamp': datetime.now().isoformat(),
            'execution_id': self.execution_id,
            'cve_id': self.cve_id,
            'event': event,
            'safety_mode': self.safety_mode,
            'data': data or {}
        }
        
        # Save to audit file
        audit_file = Path(f"/tmp/chromsploit_audit_{self.cve_id}.jsonl")
        try:
            with open(audit_file, 'a') as f:
                f.write(json.dumps(audit_entry) + '\n')
        except Exception:
            pass
    
    def _create_safe_failure_response(self, reason: str) -> Dict[str, Any]:
        """Create a safe failure response"""
        return {
            'success': False,
            'cve_id': self.cve_id,
            'error': reason,
            'safety_mode': self.safety_mode,
            'execution_id': self.execution_id,
            'timestamp': datetime.now().isoformat()
        }
    
    def _log_safe(self, message: str):
        """Log safe operation"""
        try:
            self.logger.info(f"{Colors.GREEN}[SAFE]{Colors.END} {message}")
        except:
            self.logger.info(f"[SAFE] {message}")
        
        if self.safety_mode == SafetyMode.SIMULATION:
            self.simulation_logs.append({
                'timestamp': time.time(),
                'level': 'info',
                'message': message
            })
    
    def _log_warning(self, message: str):
        """Log warning"""
        try:
            self.logger.warning(f"{Colors.YELLOW}[WARNING]{Colors.END} {message}")
        except:
            self.logger.warning(f"[WARNING] {message}")
        
        if self.safety_mode == SafetyMode.SIMULATION:
            self.simulation_logs.append({
                'timestamp': time.time(),
                'level': 'warning',
                'message': message
            })
    
    def _log_error(self, message: str):
        """Log error"""
        try:
            self.logger.error(f"{Colors.RED}[ERROR]{Colors.END} {message}")
        except:
            self.logger.error(f"[ERROR] {message}")
        
        if self.safety_mode == SafetyMode.SIMULATION:
            self.simulation_logs.append({
                'timestamp': time.time(),
                'level': 'error',
                'message': message
            })
    
    @abstractmethod
    def _execute_simulation(self, target_url: str = None) -> Dict[str, Any]:
        """Execute exploit in simulation mode - must be implemented by subclasses"""
        pass
    
    @abstractmethod
    def _execute_real(self, target_url: str = None) -> Dict[str, Any]:
        """Execute real exploit (when authorized) - must be implemented by subclasses"""
        pass
    
    def _execute_demonstration(self, target_url: str = None) -> Dict[str, Any]:
        """Execute demonstration mode - safe visual demonstration"""
        # Default to simulation
        return self._execute_simulation(target_url)
    
    def _execute_educational(self, target_url: str = None) -> Dict[str, Any]:
        """Execute educational mode - explains techniques without execution"""
        return {
            'success': True,
            'cve_id': self.cve_id,
            'mode': 'educational',
            'explanation': self._get_educational_content(),
            'techniques': self._get_technique_explanation(),
            'mitigations': self._get_mitigation_advice()
        }
    
    def _get_educational_content(self) -> str:
        """Get educational content about the vulnerability"""
        return f"""
        {self.name} ({self.cve_id})
        
        Description: {self.description}
        
        This is an educational demonstration showing how this vulnerability works
        without performing any actual exploitation.
        """
    
    def _get_technique_explanation(self) -> List[str]:
        """Get explanation of exploitation techniques"""
        return ["Override in subclass for specific techniques"]
    
    def _get_mitigation_advice(self) -> List[str]:
        """Get mitigation advice"""
        return ["Override in subclass for specific mitigations"]
    
    def cleanup(self):
        """Clean up resources safely"""
        self._log_safe(f"Cleaning up {self.cve_id} resources")
        # Override in subclasses for specific cleanup
    
    def stop(self):
        """Stop any running processes safely"""
        self._log_safe(f"Stopping {self.cve_id} processes")
        self.cleanup()